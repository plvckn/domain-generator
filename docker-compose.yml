version: "3.9"
services:
  api: 
    container_name: domain_service_api
    build:
      context: .
      dockerfile: Dockerfile
    env_file:
      - .env
    ports:
      - "${FASTAPI_PORT}:${FASTAPI_PORT}"
    command: "uvicorn run_api:app --host 0.0.0.0 --port ${FASTAPI_PORT} --workers 1"
  vllm:
    container_name: vllm
    image: vllm/vllm-openai:latest
    env_file:
      - .env
    ports:
      - "${VLLM_PORT}:${VLLM_PORT}"
    command:
      - "--model"
      - "${BASE_MODEL_NAME}"
      - "--enable-lora"
      - "--lora-modules"
      - "${FINETUNED_ADAPTER_NAME}=${FINETUNED_ADAPTER_PATH}"
      - "--dtype"
      - "bfloat16"
      - "--max-model-len"
      - "16384"
      - "--port"
      - "${VLLM_PORT}"
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    volumes:
      - ./training/finetuned_model:/models/finetuned_model
      #- ./cached_models:/root/.cache/huggingface